{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_extractor_json_path = '../sample_extractor/folderApi_u53k9a4qalbwfws7x/JSON/'\n",
    "sample_add_extractor_json_path = '../sample_extractor/folderApi_u53k97xzulc5uphr0/JSON/'\n",
    "\n",
    "sets_data = []\n",
    "\n",
    "sets = [filename for filename in os.listdir(\n",
    "    sample_extractor_json_path) if filename.startswith(\"Set-\")]\n",
    "\n",
    "master_set_datas = []\n",
    "for json_file in sorted(sets, key=lambda x: int(x[4:-5])):\n",
    "    if re.search('Set-[0-9]*.json', json_file):\n",
    "        print(sample_extractor_json_path + json_file)\n",
    "        with open(sample_extractor_json_path + json_file, 'r', encoding='utf-8-sig') as fs:\n",
    "            set_data = json.loads(fs.read())\n",
    "            master_set_datas.append(set_data)\n",
    "\n",
    "sets_data.append(master_set_datas)\n",
    "\n",
    "# htmls = [filename for filename in os.listdir(sample_add_extractor_json_path) if not filename.startswith(\"Set-\")]\n",
    "\n",
    "# for json_file in sorted(htmls, key=lambda x:int(x[:4])):\n",
    "#     if re.search('[0-9]{4}.json', json_file):\n",
    "#         print(sample_add_extractor_json_path + json_file)\n",
    "#         with open(sample_add_extractor_json_path + json_file, 'r', encoding='utf-8-sig') as fs:\n",
    "#             set_data = json.loads(fs.read())\n",
    "#             sets_data.append(set_data)\n",
    "\n",
    "sets = [filename for filename in os.listdir(\n",
    "    sample_add_extractor_json_path) if filename.startswith(\"Set-\")]\n",
    "\n",
    "master_set_datas = []\n",
    "for json_file in sorted(sets, key=lambda x: int(x[4:-5])):\n",
    "    if re.search('Set-[0-9]*.json', json_file):\n",
    "        print(sample_add_extractor_json_path + json_file)\n",
    "        with open(sample_add_extractor_json_path + json_file, 'r', encoding='utf-8-sig') as fs:\n",
    "            set_data = json.loads(fs.read())\n",
    "            master_set_datas.append(set_data)\n",
    "sets_data.append(master_set_datas)\n",
    "# print(len(sets_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCADE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../sample_extractor/folderApi_u53k97xwblcfvhq1c/Output/Json/Set-1.json\n",
      "../sample_extractor/folderApi_u53k97xwvlcfvimsz/Output/Json/Set-1.json\n"
     ]
    }
   ],
   "source": [
    "# sample_dcade_extractor_1_json_path = '../sample_extractor/folderApi_u53k97xwblcfvhq1c/Output/Json/'\n",
    "# sample_dcade_extractor_2_json_path = '../sample_extractor/folderApi_u53k97xwvlcfvimsz/Output/Json/'\n",
    "\n",
    "# sets_data = []\n",
    "\n",
    "# sets = [filename for filename in os.listdir(sample_dcade_extractor_1_json_path) if filename.startswith(\"Set-\")]\n",
    "\n",
    "# master_set_datas = []\n",
    "# for json_file in sorted(sets, key=lambda x:int(x[4:-5])):\n",
    "#     if re.search('Set-[0-9]*.json', json_file):\n",
    "#         print(sample_dcade_extractor_1_json_path + json_file)\n",
    "#         with open(sample_dcade_extractor_1_json_path + json_file, 'r', encoding='utf-8-sig') as fs:\n",
    "#             set_data = json.loads(fs.read())\n",
    "#             master_set_datas.append(set_data)\n",
    "\n",
    "# sets_data.append(master_set_datas)\n",
    "\n",
    "# sets = [filename for filename in os.listdir(sample_dcade_extractor_2_json_path) if filename.startswith(\"Set-\")]\n",
    "\n",
    "# master_set_datas = []\n",
    "# for json_file in sorted(sets, key=lambda x:int(x[4:-5])):\n",
    "#     if re.search('Set-[0-9]*.json', json_file):\n",
    "#         print(sample_dcade_extractor_2_json_path + json_file)\n",
    "#         with open(sample_dcade_extractor_2_json_path + json_file, 'r', encoding='utf-8-sig') as fs:\n",
    "#             set_data = json.loads(fs.read())\n",
    "#             master_set_datas.append(set_data)\n",
    "# sets_data.append(master_set_datas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--set matching--\n",
      "- master -\n",
      "- slave -\n",
      "--col matching--\n",
      "{1: [1]}\n",
      "set 0 done\n",
      "49.42 s\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import time\n",
    "from datetime import datetime\n",
    "from util.matching import *\n",
    "import sys\n",
    "\n",
    "# setting path\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "folder_path = '../schema_matching_data/multipage/test/Web_' + \\\n",
    "    str(datetime.now().strftime('%y%m%d%H%M%S'))\n",
    "master = sets_data[0]\n",
    "\n",
    "# start matching data\n",
    "if len(sets_data) > 1:\n",
    "    for slave in sets_data[1:]:\n",
    "        # set matching\n",
    "        print('--set matching--')\n",
    "        set_result, master_index, slave_index = sets_matching(master, slave)\n",
    "        # col matching\n",
    "        print('--col matching--')\n",
    "        master = col_matching_forDB(\n",
    "            set_result, master, slave, master_index, slave_index, model_select=2)\n",
    "\n",
    "        # for re-extraction\n",
    "        # print('--col matching--')\n",
    "        # master = col_matching_forDB(set_result, master, slave, master_index, slave_index, model_select=2, re_extraction=True)\n",
    "else:\n",
    "    print(\"Unable to combine!!!\")\n",
    "\n",
    "sets_data = master\n",
    "\n",
    "# remove sets_data less than 3\n",
    "for index, data in enumerate(deepcopy(sets_data)):\n",
    "    if len(data) < 3:\n",
    "        sets_data.remove(data)\n",
    "\n",
    "# check if folder path exists\n",
    "if not os.path.exists(folder_path):\n",
    "    os.makedirs(folder_path)\n",
    "\n",
    "for set_index, set_data in enumerate(sets_data):\n",
    "    with open(f\"{folder_path}/Set-{str(set_index)}.json\", 'w') as fs:\n",
    "        json.dump(set_data, fs)\n",
    "\n",
    "end = time.time()\n",
    "print(\"{:.2f} s\".format(end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#nonset matching   \\n# remove set data from html\\n# read set data\\ndata = col_result[\\'setsData\\'] # set data\\n#open orig html\\n\\nfs=codecs.open(\"./nonsetdata/test/0000.html\", \\'r\\')\\nsoup = BeautifulSoup(fs, \\'lxml\\')\\n#delete tag\\nfor dim1 in data:\\n    for dim2 in dim1:\\n        for dim3 in dim2:\\n            print(dim3)\\n            try:\\n                for replace_ in soup.findAll(text=dim3):\\n                    #print(replace_)\\n                    replace_.replace_with(replace_.replace(dim3,\"\"))\\n                    #(replace_.parent).decompose()\\n            except:\\n                continue\\nfor x in soup.find_all():\\n    if len(x.get_text(strip=True)) == 0:\\n        print(x.extract())\\n#save to new html \\nwith open(\"save/to/new/html/0000.html\", \"w\") as file:\\n    file.write(str(soup))\\n#將新存好的html 去跑DCADE \\n#DCADE 要去呼叫jar\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#nonset matching   \n",
    "# remove set data from html\n",
    "# read set data\n",
    "data = col_result['setsData'] # set data\n",
    "#open orig html\n",
    "\n",
    "fs=codecs.open(\"./nonsetdata/test/0000.html\", 'r')\n",
    "soup = BeautifulSoup(fs, 'lxml')\n",
    "#delete tag\n",
    "for dim1 in data:\n",
    "    for dim2 in dim1:\n",
    "        for dim3 in dim2:\n",
    "            print(dim3)\n",
    "            try:\n",
    "                for replace_ in soup.findAll(text=dim3):\n",
    "                    #print(replace_)\n",
    "                    replace_.replace_with(replace_.replace(dim3,\"\"))\n",
    "                    #(replace_.parent).decompose()\n",
    "            except:\n",
    "                continue\n",
    "for x in soup.find_all():\n",
    "    if len(x.get_text(strip=True)) == 0:\n",
    "        print(x.extract())\n",
    "#save to new html \n",
    "with open(\"save/to/new/html/0000.html\", \"w\") as file:\n",
    "    file.write(str(soup))\n",
    "#將新存好的html 去跑DCADE \n",
    "#DCADE 要去呼叫jar\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
