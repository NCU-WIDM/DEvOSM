{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run on TensorFlow 2.x\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# The following lines adjust the granularity of reporting. \n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format\n",
    "\n",
    "# The following line improves formatting when ouputting NumPy arrays.\n",
    "np.set_printoptions(linewidth = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_features, train_label, epochs,\n",
    "                batch_size=None, validation_split=0.1):\n",
    "    \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "    history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True, \n",
    "                      validation_split=validation_split)\n",
    "\n",
    "    # To track the progression of training, gather a snapshot\n",
    "    # of the model's metrics at each epoch. \n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "\n",
    "    return epochs, hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(my_learning_rate,class_num):\n",
    "    \n",
    "    \n",
    "    \"\"\"Create and compile a deep neural net.\"\"\"\n",
    "\n",
    "    # All models in this course are sequential.\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "    # 384-element array.\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(389,)))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(units=300, activation='relu'))\n",
    "  \n",
    "    model.add(tf.keras.layers.Dense(units=256, activation='relu'))\n",
    "\n",
    "    # Define the first hidden layer.   \n",
    "    model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "    # Define a dropout regularization layer. \n",
    "  \n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "    \n",
    "    # Define a dropout regularization layer. \n",
    "    model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "    # Define the output layer. The units parameter is set to class_num because\n",
    "    # the model must choose among class_num possible output values (representing\n",
    "    # Don't change this layer.\n",
    "    model.add(tf.keras.layers.Dense(units=class_num, activation='softmax'))     \n",
    "\n",
    "    # Construct the layers into a model that TensorFlow can execute.  \n",
    "    # Notice that the loss function for multi-class classification\n",
    "    # is different than the loss function for binary classification.  \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=['accuracy',f1_m,precision_m, recall_m]\n",
    "                )\n",
    "    #metrics=['accuracy']\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded the plot_curve function.\n"
     ]
    }
   ],
   "source": [
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "    \"\"\"Plot a curve of one or more classification metrics vs. epoch.\"\"\"  \n",
    "    # list_of_metrics should be one of the names shown in:\n",
    "    # https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#define_the_model_and_metrics  \n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Value\")\n",
    "\n",
    "    for m in list_of_metrics:\n",
    "        x = hist[m]\n",
    "        plt.plot(epochs[1:], x[1:], label=m)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "print(\"Loaded the plot_curve function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_features, train_label, epochs,\n",
    "                batch_size=None, validation_split=0.1):\n",
    "    \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "    history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True, \n",
    "                      validation_split=validation_split)\n",
    "\n",
    "    # To track the progression of training, gather a snapshot\n",
    "    # of the model's metrics at each epoch. \n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "\n",
    "    return epochs, hist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
